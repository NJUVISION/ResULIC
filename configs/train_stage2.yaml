data:
  target: dataset.data_module.DataModule
  params:
    # Path to training set configuration file.
    train_config: ./configs/dataset/lic_train.yaml
    # Path to validation set configuration file.
    val_config: ./configs/dataset/lic_valid.yaml

model:
  # You can set learning rate in the following configuration file.
  config: /workspace/test/DiffEIC/configs/model/stage2/1_1_4/cldm_eps_300_ddpm.yaml
  # Path to the checkpoints or weights you want to resume. At the begining, 
  resume: ~

lightning:
  seed: 42
  
  trainer:
    strategy: ddp
    precision: 32
    # Indices of GPUs used for training.
    gpus: 2
    # Path to save logs and checkpoints.
    default_root_dir: ./logs_3/1_1_6_add_xs_eps_300_stage2
    # Max number of training steps (batches).
    max_steps: 600001
    # Validation frequency in terms of training steps.
    # val_check_interval: 5000
    log_every_n_steps: 100
    # Accumulate gradients from multiple batches so as to increase batch size.
    accumulate_grad_batches: 1
  
  callbacks:
    - target: model.callbacks.ImageLogger
      params:
        # Log frequency of image logger.
        log_every_n_steps: 1000
        log_start_step: 0
        max_images_each_step: 2
        log_images_kwargs: ~

    - target: model.callbacks.ModelCheckpoint
      params:
        # Frequency of saving checkpoints.
        every_n_train_steps: 20000
        save_top_k: -1
        filename: "{step}"
